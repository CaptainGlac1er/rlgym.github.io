"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[997],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),s=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},u=function(e){var t=s(e.components);return r.createElement(c.Provider,{value:t},e.children)},p="mdxType",f={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,c=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=s(n),m=o,d=p["".concat(c,".").concat(m)]||p[m]||f[m]||i;return n?r.createElement(d,a(a({ref:t},u),{},{components:n})):r.createElement(d,a({ref:t},u))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,a=new Array(i);a[0]=m;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[p]="string"==typeof e?e:o,a[1]=l;for(var s=2;s<i;s++)a[s]=n[s];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5365:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var r=n(7462),o=(n(7294),n(3905));const i={title:"Configuration Objects"},a=void 0,l={unversionedId:"tutorials/introduction_to_configuration_objects",id:"tutorials/introduction_to_configuration_objects",title:"Configuration Objects",description:"Configuration Objects",source:"@site/docs/tutorials/introduction_to_configuration_objects.md",sourceDirName:"tutorials",slug:"/tutorials/introduction_to_configuration_objects",permalink:"/rlgym.github.io/docs/tutorials/introduction_to_configuration_objects",draft:!1,tags:[],version:"current",frontMatter:{title:"Configuration Objects"},sidebar:"tutorialSidebar",previous:{title:"Action Parsers",permalink:"/rlgym.github.io/docs/tutorials/action_parsers"},next:{title:"Observation Builders",permalink:"/rlgym.github.io/docs/tutorials/observation_builders"}},c={},s=[{value:"Configuration Objects",id:"configuration-objects",level:2}],u={toc:s};function p(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"configuration-objects"},"Configuration Objects"),(0,o.kt)("p",null,"At their core, RLGym environments are configured with 3 basic objects:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"A ",(0,o.kt)("a",{parentName:"li",href:"https://rlgym.github.io/docs-page.html#reward-functions"},"RewardFunction")),(0,o.kt)("li",{parentName:"ol"},"An ",(0,o.kt)("a",{parentName:"li",href:"https://rlgym.github.io/docs-page.html#observation-builders"},"ObsBuilder")),(0,o.kt)("li",{parentName:"ol"},"A list of ",(0,o.kt)("a",{parentName:"li",href:"https://rlgym.github.io/docs-page.html#terminal-conditions"},"TerminalCondition")," objects")),(0,o.kt)("p",null,"RLGym uses these objects at every step."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"To determine what reward should be assigned to each action."),(0,o.kt)("li",{parentName:"ul"},"What observation should be returned to the agent."),(0,o.kt)("li",{parentName:"ul"},"When an episode should be terminated.")),(0,o.kt)("p",null,"The flowchart below depicts how each of these objects is used by RLGym."),(0,o.kt)("mermaid",{value:"%%{\n  init: {\n    'theme': 'base',\n    'themeVariables': {\n      'primaryColor': '#6f48c0',\n      'primaryTextColor': '#fff',\n      'primaryBorderColor': '#5d2c84',\n      'lineColor': '#808080',\n      'secondaryColor': '#8d8d8d',\n      'tertiaryColor': '#fff'\n    },\n    'flowchart': { 'curve': 'bump' }\n  }\n}%%\nflowchart TB\n    A[State Setter] --\x3e|Initial State| B[Environment]\n    B --\x3e C{{Player, Game State, Action}}\n    C --\x3e D[ObsBuilder]\n    C --\x3e E[RewardFunction]\n    C --\x3e F[TerminalConditions]\n    D --\x3e|Next Observation| G[Learning Algorithm]\n    E --\x3e|Reward| G\n    F --\x3e|Done| G\n    G --\x3e|Observation| H[Agent]\n    H --\x3e|Action| B"}),(0,o.kt)("p",null,"RLGym comes with a few of these objects implemented out of the box to provide users with inspiration when creating their own.\nThe default configuration objects for any RLGym environment can be overridden by simply passing instances of a desired configuration object to the optional arguments of ",(0,o.kt)("inlineCode",{parentName:"p"},"make"),"."))}p.isMDXComponent=!0}}]);